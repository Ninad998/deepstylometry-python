{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import ANNModelCreatorWordGender as md\n",
    "\n",
    "dimensions = 50\n",
    "embedfile = 'glove.6B.' + str(dimensions) + 'd.txt'\n",
    "authorList = [21,63,27,88] \n",
    "doc_id = 85\n",
    "chunk_size = 1000\n",
    "nb_epoch = 30\n",
    "glove = '../../glove/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level = Word\n",
      "File used: glove.6B.50d.txt\n",
      "Found 400000 word vectors.\n",
      "Found 173177 unique tokens.\n",
      "Execution completed\n",
      "Read completed\n",
      "Number of rows: 1\n",
      "gender         object\n",
      "doc_content    object\n",
      "dtype: object\n",
      "Data Frame created: Shape: (43, 2)\n",
      "Found 43 texts.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = md.readVectorData(embedfile, GLOVE_DIR=glove)\n",
    "\n",
    "md.makeTokenizer()\n",
    "\n",
    "labels_index = {\n",
    "    0: 'M',\n",
    "    1: 'F'\n",
    "}\n",
    "\n",
    "genderList = ['M', 'F']\n",
    "\n",
    "(testX, testY) = md.loadDocData(doc_id, genderList, chunk_size = chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN THE CAGE CHAPTER I It had occurred to her early that in her position -- that of a young person spending , in framed and wired confinement , the life of a guinea-pig or a magpie -- she should know a great many persons without their recognising the acquaintance . That made it an emotion the more lively -- though singularly rare and always , even then , with opportunity still very much smothered -- to see any one come in whom she knew outside , as she called it , any one who could add anything to the meanness of her function . Her function was to sit there with two young men -- the other telegraphist and the counter-clerk ; to mind the `` sounder , '' which was always going , to dole out stamps and postal-orders , weigh letters , answer stupid questions , give difficult change and , more than anything else , count words as numberless as the sands of the sea , the words of the telegrams thrust , from morning to night , through the gap left in the high lattice , across the encumbered shelf that her forearm ached with rubbing . This transparent screen fenced out or fenced in , according to the side of the narrow counter on which the human lot was cast , the duskiest corner of a shop pervaded not a little , in winter , by the poison of perpetual gas , and at all times by the presence of hams , cheese , dried fish , soap , varnish , paraffin and other solids and fluids that she came to know perfectly by their smells without consenting to know them by their names . The barrier that divided the little post-and-telegraph-office from the grocery was a frail structure of wood and wire ; but the social , the professional separation was a gulf that fortune , by a stroke quite remarkable , had spared her the necessity of contributing at all publicly to bridge . When Mr. Cocker 's young men stepped over from behind the other counter to change a five-pound note -- and Mr. Cocker 's situation , with the cream of the `` Court Guide '' and the dearest furnished apartments , Simpkin 's , Ladle 's , Thrupp 's , just round the corner , was so select that his place was quite pervaded by the crisp rustle of these emblems -- she pushed out the sovereigns as if the applicant were no more to her than one of the momentary , the practically featureless , appearances in the great procession ; and this perhaps all the more from the very fact of the connexion ( only recognised outside indeed ) to which she had lent herself with ridiculous inconsequence . She recognised the others the less because she had at last so unreservedly , so irredeemably , recognised Mr. Mudge . However that might be , she was a little ashamed of having to admit to herself that Mr. Mudge 's removal to a higher sphere -- to a more commanding position , that is , though to a much lower neighbourhood -- would have been described still better as a luxury than as the mere simplification , the corrected awkwardness , that she contented herself with calling it . He had at any rate ceased to be all day long in her eyes , and this left something a little fresh for them to rest on of a Sunday . During the three months of his happy survival at Cocker 's after her consent to their engagement she had often asked herself what it was marriage would be able to add to a familiarity that seemed already to have scraped the platter so clean . Opposite there , behind the counter of which his superior stature , his whiter apron , his more clustering curls and more present , too present , _h_ 's had been for a couple of years the principal ornament , he had moved to and fro before her as on the small sanded floor of their contracted future . She was conscious now of the improvement of not having to take her present and her future at once . They were about as much as she could manage when taken separate . She had , none the less , to give her mind steadily to what Mr. Mudge had again written her about , the idea of her applying for a transfer to an office quite similar -- she could n't yet hope for a place in a bigger -- under the very roof where he was foreman , so that , dangled before her every minute of the day , he should see her , as he called it , `` hourly , '' and in a part , the far N.W . district , where , with her mother , she would save on their two rooms alone nearly three shillings . It would be far from dazzling to exchange Mayfair for Chalk Farm , and it wore upon her much that he could never drop a subject ; still , it did n't wear as things _had_ worn , the worries of the early times of their great misery , her own , her mother 's and her elder sister 's -- the last of whom had succumbed to all but absolute want when , as conscious and incredulous ladies , suddenly bereft , betrayed , overwhelmed , they had slipped faster and faster down the steep slope at the bottom of which she alone had rebounded . Her mother had never rebounded any more at the bottom than on the way ; had only rumbled and grumbled down and down , making , in respect of caps , topics and `` habits , '' no effort whatever -- which simply meant smelling much of the time of whiskey\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print testX[0]\n",
    "print testY[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 173177 unique tokens.\n",
      "Shape of data tensor: (43, 1000)\n"
     ]
    }
   ],
   "source": [
    "(testX, testY) = md.preProcessTest(testX, labels_index, testY, chunk_size = chunk_size)\n",
    "# testY = np.mean(testY, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     6     1  6119   393     7\n",
      "    12    18  1523     4    14   534     8     6    14   675     8     3\n",
      "     5   142   449  4835     6  6877     2 26550  8833     1   131     3\n",
      "     5  8583  3949    48     5 16157    20    87    86     5   103   155\n",
      "  1037   151    56 17643     1  1449     8    92    12    52  2268     1\n",
      "    63  2144   129  5455  2391     2   163   128    65    16  1138   143\n",
      "    64    82  6881     4    83    81    42   100     6   231    20   195\n",
      "   806    17    20   253    12    81    42    57    61  1979   259     4\n",
      "     1 12799     3    14  8365    14  8365    10     4   645    44    16\n",
      "   104   142   136     1    99     2     1  4793  2486     4   182     1\n",
      " 21551     9    37    10   163   187     4 23938    62 14151     2 24198\n",
      "  1068  7664   600   411  2526  1052   189  1091   555     2    63    73\n",
      "   259   409  1317   266    17 14289    17     1  5118     3     1   385\n",
      "     1   266     3     1 17254  2206    39   257     4   174   145     1\n",
      "  7111   192     6     1   332 13094   474     1 12657  5969     8    14\n",
      " 34867  6959    16  6633    38  6973  5428 15690    62    48 15690     6\n",
      "  1195     4     1   240     3     1  1132  4793    26    37     1   533\n",
      "  1191    10   965     1   790     3     5  1764  9437    21     5    67\n",
      "     6   836    32     1  4346     3  3861  4951     2    25    31   386\n",
      "    32     1   704     3 27770  5736  4199  1598  8462 25173     2    99\n",
      "     2 34300     8    20   107     4    86   763    32    56 10949   151\n",
      " 15573     4    86    55    32    56  1296     1  6182     8  2613     1\n",
      "    67  1172     2  6595   846    39     1 23528    10     5  6264  4262\n",
      "     3   783     2  6250    23     1  1710     1  5303  4290    10     5\n",
      "  4868     8  1022    32     5  3055   186  1731    18  2792    14     1\n",
      "  1721     3 19809    25    31  7461     4  1496    51    80    27   142\n",
      "   136  1941    90    39   342     1    99  4793     4   555     5   408\n",
      "  5128   722     2    80    27  1217    16     1  4950     3     1   621\n",
      "  1705     9     2     1  1583  3202  4746 28461    27 36080    27    27\n",
      "   133   225     1   790    10    36  6841     8    13   171    10   186\n",
      "  9437    32     1  9179  8857     3   114 20106    20  2062    62     1\n",
      "  9366    17    49     1 25982    41    47    63     4    14    73    42\n",
      "     3     1  4702     1  4234 34879  6112     6     1   103  3707     2\n",
      "    38   248    31     1    63    39     1    64   374     3     1  7890\n",
      "    75  3988   806   244     4    37    20    18  3935   199    16  3065\n",
      "    20  3988     1   321     1   310   215    20    18    25   141    36\n",
      " 17710    36  3988    80   261     8   120    24    20    10     5    67\n",
      "  1437     3   230     4  1799     4   199     8    80    27  6993     4\n",
      "     5  1259  5216     4     5    63  5463   675     8    22   129     4\n",
      "     5    82  1229  2581    43    28    50  1988   143   179    17     5\n",
      "  3994    73    17     1   698     1  8773 10667     8    20  3259   199\n",
      "    16  1397    12    11    18    25    81   989  1552     4    24    31\n",
      "   111   124     6    14   140     2    38   192   196     5    67   693\n",
      "    19    55     4   318    26     3     5   959   482     1   207   730\n",
      "     3    13   356 18066    25    27    98    14  1727     4    56  2424\n",
      "    20    18   333   201   199    54    12    10   787    43    24   444\n",
      "     4  1979     4     5  6865     8   176   381     4    28 13570     1\n",
      " 14216    36  1634  1159    44   342     1  4793     3    37    13  1825\n",
      "  7284    13 14794  4572    13    63 15459  3683     2    63   303   117\n",
      "   303  1947    27    18    50    19     5  1591     3   217     1  2662\n",
      "  5188    11    18   827     4     2  3086    95    14    17    26     1\n",
      "   300 26823   929     3    56  7156   788    20    10  1390    68     3\n",
      "     1  3698     3    21   230     4   146    14   303     2    14   788\n",
      "    25   157    35    41    77    17    82    17    20    61  2415    51\n",
      "   288  2728    20    18   512     1   310     4   189    14   182  2659\n",
      "     4    54    80    18   125   678    14    77     1   490     3    14\n",
      "  9666    19     5 11268     4    52   846   186  2262    20    61    58\n",
      "   147   262    19     5   171     6     5  5819   181     1    64  1671\n",
      "   119    11    10 12592    36     8 22816    95    14   144   808     3\n",
      "     1   111    11    87    83    14    17    11   253    12 13028     9\n",
      "     2     6     5   241     1   200  3092  2645  3650   119    16    14\n",
      "   164    20    43   571    26    56   104  1220   304   564   207  5291\n",
      "    12    43    24   200    39  6471     4  3237 36074    19  5769  1726\n",
      "     2    12  1249   101    14    82     8    11    61    88  1606     5\n",
      "   514   143    12    69    58  1399    17   183    18  1254     1 12352\n",
      "     3     1   534   386     3    56   103  1733    14   105    14   164\n",
      "    27     2    14  1563   329    27     1   141     3   231    18 16507\n",
      "     4    31    23  2113   237    51    17  1390     2 10950   573   466\n",
      " 15375  2680  6544    35    18  2155  4974     2  4974    91     1  3126\n",
      "  3101    25     1  1415     3    37    20   304    18    14   164    18\n",
      "    88    81    63    25     1  1415    73    26     1   118    18    75\n",
      " 23107     2  7527    91     2    91   364     6   860     3  5600  9266\n",
      "     2  1687     9    47  1157   636    37  1059   601  9240    82     3\n",
      "     1    78     3 11918]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print testX[0]\n",
    "print testY[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = md.prepareEmbeddingMatrix(embeddings_index, EMBEDDING_DIM = dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done compiling.\n"
     ]
    }
   ],
   "source": [
    "model = md.recompileModel(len(labels_index), embedding_matrix, chunk_size = chunk_size, EMBEDDING_DIM = dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(predYList, predY) = md.predictModel(model, testX, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'M', 1: 'F'}\n"
     ]
    }
   ],
   "source": [
    "print labels_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99616861  0.00383141]\n"
     ]
    }
   ],
   "source": [
    "print predY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97113478  0.02886529]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print np.mean(predYList, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.97831726  0.02168269]\n",
      " [ 0.99725527  0.00274473]\n",
      " [ 0.98790342  0.01209657]\n",
      " [ 0.99437201  0.00562791]\n",
      " [ 0.98457319  0.01542683]\n",
      " [ 0.99245268  0.00754733]\n",
      " [ 0.99370897  0.00629102]\n",
      " [ 0.86620671  0.13379332]\n",
      " [ 0.98921275  0.01078722]\n",
      " [ 0.99369568  0.00630431]\n",
      " [ 0.99352139  0.0064786 ]\n",
      " [ 0.99666178  0.0033383 ]\n",
      " [ 0.99364662  0.00635343]\n",
      " [ 0.99523818  0.00476184]\n",
      " [ 0.99658978  0.00341023]\n",
      " [ 0.4596085   0.5403915 ]\n",
      " [ 0.99238139  0.00761864]\n",
      " [ 0.9936173   0.00638275]\n",
      " [ 0.99666291  0.00333704]\n",
      " [ 0.99418205  0.00581788]\n",
      " [ 0.99659342  0.00340656]\n",
      " [ 0.99666578  0.00333422]\n",
      " [ 0.97526419  0.02473586]\n",
      " [ 0.88278484  0.11721521]\n",
      " [ 0.99574584  0.00425422]\n",
      " [ 0.99509227  0.00490772]\n",
      " [ 0.99385154  0.0061485 ]\n",
      " [ 0.99092627  0.00907375]\n",
      " [ 0.99501747  0.00498256]\n",
      " [ 0.99662966  0.00337035]\n",
      " [ 0.99687469  0.00312531]\n",
      " [ 0.99288893  0.00711104]\n",
      " [ 0.99625695  0.00374303]\n",
      " [ 0.99657106  0.00342891]\n",
      " [ 0.99547559  0.00452442]\n",
      " [ 0.98530859  0.01469138]\n",
      " [ 0.99521989  0.00478014]\n",
      " [ 0.99712062  0.00287936]\n",
      " [ 0.99623138  0.00376858]\n",
      " [ 0.99578828  0.00421177]\n",
      " [ 0.99660313  0.00339685]\n",
      " [ 0.99524659  0.00475339]\n",
      " [ 0.81082815  0.18917185]]\n"
     ]
    }
   ],
   "source": [
    "print predYList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
