{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3)\n",
      "doc_id         int64\n",
      "author_id      int64\n",
      "authorList    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('queryset_CNN.csv')\n",
    "print(df.shape)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current test: doc_id = 85, candidate = 3, dimensions = 200, samples = 3200, \n",
      "iterations = 10, dropout = 0.5, test = pretrained_feat_oneVsSVC\n",
      "Execution completed\n",
      "Running: doc_id = 85, candidate = 3, dimensions = 200, samples = 3200, \n",
      "iterations = 10, dropout = 0.5, test = pretrained_feat_oneVsSVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 950 (CNMeM is disabled, cuDNN 5110)\n",
      "/home/ninadt/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level = Word\n",
      "File used: glove.6B.200d.txt\n",
      "Found 400000 word vectors.\n",
      "Execution completed\n",
      "Read completed\n",
      "Number of rows: 124\n",
      "author_id       int64\n",
      "doc_content    object\n",
      "dtype: object\n",
      "Data Frame created: Shape: (11577, 2)\n",
      "Author:    44  Size:  4745\n",
      "Author:    64  Size:  5106\n",
      "Author:    82  Size:  1726\n",
      "Min: 1726\n",
      "Max: 5106\n",
      "Authors [44, 64, 82].\n",
      "Found 5178 texts.\n",
      "Found 5178 labels.\n",
      "Found 46309 unique tokens.\n",
      "Shape of data tensor: (5178, 1000)\n",
      "Shape of label tensor: (5178, 3)\n",
      "Done compiling.\n",
      "Done compiling.\n",
      "Found 46309 unique tokens.\n",
      "Shape of data tensor: (5178, 1000)\n",
      "Shape of label tensor: (5178,)\n",
      "\n",
      "\n",
      "Final Train Accuracy: 81.31\n",
      "\n",
      "Final Validation Accuracy: 74.13\n",
      "Level = Word\n",
      "File used: glove.6B.200d.txt\n",
      "Found 400000 word vectors.\n",
      "Found 46399 unique tokens.\n",
      "Execution completed\n",
      "Read completed\n",
      "Number of rows: 1\n",
      "author_id       int64\n",
      "doc_content    object\n",
      "dtype: object\n",
      "Data Frame created: Shape: (43, 2)\n",
      "Found 43 texts.\n",
      "Found 46399 unique tokens.\n",
      "Shape of data tensor: (43, 1000)\n",
      "Done compiling.\n",
      "Done compiling.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "integer argument expected, got float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-df79c2722ffe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mdoc_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthorList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauthorList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../../glove/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             samples = samples, nb_epoch = iterations, dropout = dropout, batch_size = 10 )\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ninadt/Data/deepstylometry-python/fyp/ipynb/StyloNeuralML.pyc\u001b[0m in \u001b[0;36mgetTestResults\u001b[0;34m(authorList, doc_id, labels_index, algo, chunk_size, nb_epoch, level, glove, samples, dimensions, dropout, batch_size)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mtestY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mpredY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthorList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ninadt/Data/deepstylometry-python/fyp/ipynb/CNNModelCreatorWordEdit.pyc\u001b[0m in \u001b[0;36mpredictModel\u001b[0;34m(feature_model, mlmodel, testX, authorList)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0mpredval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0mpredval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredcount\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m         \u001b[0mpredYprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0mpredYprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredYprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: integer argument expected, got float"
     ]
    }
   ],
   "source": [
    "\n",
    "for index, row in df.iterrows():\n",
    "    doc_id = row.doc_id\n",
    "\n",
    "    author_id = row.author_id\n",
    "\n",
    "    import ast\n",
    "    authorList = ast.literal_eval(row.authorList)\n",
    "    \n",
    "    candidate = len(authorList)\n",
    "    \n",
    "    algo = \"oneVsSVC\"\n",
    "    \n",
    "    test = str(\"pretrained_feat_\" + algo) # change before run\n",
    "    \n",
    "    test = str(\"pretrained_feat_\" + algo) # change before run\n",
    "    \n",
    "    level = \"word\"\n",
    "    \n",
    "    iterations = 10\n",
    "\n",
    "    dropout = 0.5\n",
    "\n",
    "    samples = 3200\n",
    "\n",
    "    dimensions = 200\n",
    "\n",
    "    loc = authorList.index(author_id)\n",
    "\n",
    "    printstate = ((\"doc_id = %s, candidate = %s, \") % (str(doc_id), str(candidate)))\n",
    "    printstate += ((\"dimensions = %s, samples = %s, \") % (str(dimensions), str(samples)))\n",
    "    printstate += ((\"\\niterations = %s, dropout = %s, test = %s\") % (str(iterations), str(dropout), str(test)))\n",
    "\n",
    "    print(\"Current test: %s\" % (str(printstate)))\n",
    "    \"\"\"\n",
    "    from sshtunnel import SSHTunnelForwarder\n",
    "    with SSHTunnelForwarder(('144.214.121.15', 22),\n",
    "                            ssh_username='ninadt',\n",
    "                            ssh_password='Ninad123',\n",
    "                            remote_bind_address=('localhost', 3306),\n",
    "                            local_bind_address=('localhost', 3302)):\n",
    "    \"\"\"\n",
    "    import UpdateDB as db\n",
    "    case = db.checkOldCNNDiff(doc_id = doc_id, candidate = candidate, dimensions = dimensions,\n",
    "                              samples = samples, iterations = iterations, dropout = dropout,\n",
    "                              test = test)\n",
    "\n",
    "    if case == False:\n",
    "\n",
    "        print(\"Running: %12s\" % (str(printstate)))\n",
    "\n",
    "        import StyloNeuralML as Stylo\n",
    "        (labels_index, train_acc, val_acc, samples) = Stylo.getResults(\n",
    "            doc_id = doc_id, authorList = authorList[:], algo = algo,\n",
    "            level = level, glove = '../../glove/', dimensions = dimensions, \n",
    "            samples = samples, nb_epoch = iterations, dropout = dropout, batch_size = 10 )\n",
    "        \n",
    "        (predY, testY) = Stylo.getTestResults(\n",
    "            doc_id = doc_id, authorList = authorList[:], labels_index = labels_index, algo = algo,\n",
    "            level = level, glove = '../../glove/', dimensions = dimensions, \n",
    "            samples = samples, nb_epoch = iterations, dropout = dropout, batch_size = 10 )\n",
    "            \n",
    "        loc = testY\n",
    "        \n",
    "        test_acc = 0.0\n",
    "        \n",
    "        test_acc = predY[loc]\n",
    "\n",
    "        test_bin = 0\n",
    "\n",
    "        if(predY.tolist().index(max(predY)) == testY):\n",
    "            test_bin = 1\n",
    "        \n",
    "        \"\"\"\n",
    "        from sshtunnel import SSHTunnelForwarder\n",
    "        with SSHTunnelForwarder(('144.214.121.15', 22),\n",
    "                                ssh_username='ninadt',\n",
    "                                ssh_password='Ninad123',\n",
    "                                remote_bind_address=('localhost', 3306),\n",
    "                                local_bind_address=('localhost', 3302)):\n",
    "        \"\"\"\n",
    "        import UpdateDB as db\n",
    "        case = db.updateresultOldCNNDiff(doc_id = doc_id, candidate = candidate, dimensions = dimensions,\n",
    "                                         samples = samples, iterations = iterations, dropout = dropout, \n",
    "                                         train_acc = train_acc, val_acc = val_acc,\n",
    "                                         test_acc = test_acc, test_bin = test_bin,\n",
    "                                         test = test)\n",
    "        del Stylo\n",
    "\n",
    "        #from keras import backend as K\n",
    "        #K.clear_session()\n",
    "        \n",
    "        import time\n",
    "        time.sleep(10)\n",
    "\n",
    "        from IPython.display import clear_output\n",
    "\n",
    "        clear_output()\n",
    "\n",
    "    else:\n",
    "        print(\"Skipped: %12s\" % (str(printstate)))\n",
    "\n",
    "# import pandas as pd\n",
    "# df = pd.DataFrame(output)\n",
    "# df.to_csv(\"styloout.csv\", index = False, encoding='utf-8')\n",
    "\n",
    "import time\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
