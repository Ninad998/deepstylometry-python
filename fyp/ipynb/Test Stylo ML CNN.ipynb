{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('queryset_CNN_SVC.csv')\n",
    "print(df.shape)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for index, row in df.iterrows():\n",
    "    doc_id = row.doc_id\n",
    "\n",
    "    author_id = row.author_id\n",
    "\n",
    "    import ast\n",
    "    authorList = ast.literal_eval(row.authorList)\n",
    "    \n",
    "    candidate = len(authorList)\n",
    "    \n",
    "    algo = \"svc\"\n",
    "    \n",
    "    test = str(algo + \"_256\") # change before run\n",
    "    \n",
    "    level = \"word\"\n",
    "    \n",
    "    iterations = 30\n",
    "\n",
    "    dropout = 0.5\n",
    "\n",
    "    samples = 3200\n",
    "\n",
    "    dimensions = 200\n",
    "\n",
    "    loc = authorList.index(author_id)\n",
    "\n",
    "    printstate = ((\"doc_id = %s, candidate = %s, \") % (str(doc_id), str(candidate)))\n",
    "    printstate += ((\"dimensions = %s, samples = %s, \") % (str(dimensions), str(samples)))\n",
    "    printstate += ((\"\\niterations = %s, dropout = %s, test = %s\") % (str(iterations), str(dropout), str(test)))\n",
    "\n",
    "    print(\"Current test: %s\" % (str(printstate)))\n",
    "    \n",
    "    \"\"\"\n",
    "    from sshtunnel import SSHTunnelForwarder\n",
    "    with SSHTunnelForwarder(('144.214.121.15', 22),\n",
    "                            ssh_username='ninadt',\n",
    "                            ssh_password='Ninad123',\n",
    "                            remote_bind_address=('localhost', 3306),\n",
    "                            local_bind_address=('localhost', 3300)):\n",
    "    \"\"\"\n",
    "    import UpdateDB as db\n",
    "    case = db.checkOldCNNDiffBoth(doc_id = doc_id, candidate = candidate, dimensions = dimensions,\n",
    "                                  samples = samples, iterations = iterations, dropout = dropout,\n",
    "                                  test = test)\n",
    "    \n",
    "    if case == False:\n",
    "        \n",
    "        print(\"Running: %12s\" % (str(printstate)))\n",
    "\n",
    "        import StyloNeural as Stylo\n",
    "        (labels_index, history, train_acc_cnn, val_acc_cnn, samples) = Stylo.getResults(\n",
    "            doc_id = doc_id, authorList = authorList[:], \n",
    "            level = level, glove = '../../glove/', dimensions = dimensions, \n",
    "            samples = samples, nb_epoch = iterations, dropout = dropout, batch_size = 10 )\n",
    "\n",
    "        (predY_cnn, testY_cnn) = Stylo.getTestResults(\n",
    "            doc_id = doc_id, authorList = authorList[:], labels_index = labels_index,\n",
    "            level = level, glove = '../../glove/', dimensions = dimensions, \n",
    "            samples = samples, nb_epoch = iterations, dropout = dropout, batch_size = 10 )\n",
    "\n",
    "        del Stylo\n",
    "\n",
    "        from keras import backend as K\n",
    "        K.clear_session()\n",
    "\n",
    "        from IPython.display import clear_output\n",
    "\n",
    "        clear_output()\n",
    "\n",
    "        import StyloNeuralML as Stylo\n",
    "        (labels_index, train_acc_ml, val_acc_ml, samples) = Stylo.getResults(\n",
    "            doc_id = doc_id, authorList = authorList[:], algo = algo,\n",
    "            level = level, glove = '../../glove/', dimensions = dimensions, \n",
    "            samples = samples, nb_epoch = iterations, dropout = dropout, batch_size = 10 )\n",
    "\n",
    "        (predY_ml, testY_ml) = Stylo.getTestResults(\n",
    "            doc_id = doc_id, authorList = authorList[:], labels_index = labels_index, algo = algo,\n",
    "            level = level, glove = '../../glove/', dimensions = dimensions, \n",
    "            samples = samples, nb_epoch = iterations, dropout = dropout, batch_size = 10 )\n",
    "\n",
    "        del Stylo\n",
    "\n",
    "        from keras import backend as K\n",
    "        K.clear_session()\n",
    "\n",
    "        loc = testY_cnn\n",
    "\n",
    "        test_acc_cnn = 0.0\n",
    "\n",
    "        test_acc_cnn = predY_cnn[loc]\n",
    "\n",
    "        test_bin_cnn = 0\n",
    "\n",
    "        if(predY_cnn.tolist().index(max(predY_cnn)) == testY_cnn):\n",
    "            test_bin_cnn = 1\n",
    "\n",
    "        loc = testY_ml\n",
    "\n",
    "        test_acc_ml = 0.0\n",
    "\n",
    "        test_acc_ml = predY_ml[loc]\n",
    "\n",
    "        test_bin_ml = 0\n",
    "\n",
    "        if(predY_ml.tolist().index(max(predY_ml)) == testY_ml):\n",
    "            test_bin_ml = 1\n",
    "            \n",
    "        \"\"\"\n",
    "        from sshtunnel import SSHTunnelForwarder\n",
    "        with SSHTunnelForwarder(('144.214.121.15', 22),\n",
    "                                ssh_username='ninadt',\n",
    "                                ssh_password='Ninad123',\n",
    "                                remote_bind_address=('localhost', 3306),\n",
    "                                local_bind_address=('localhost', 3300)):\n",
    "        \"\"\"\n",
    "        import UpdateDB as db\n",
    "        case = db.updateresultOldCNNDiffBoth(\n",
    "            doc_id = doc_id, candidate = candidate, dimensions = dimensions,\n",
    "            samples = samples, iterations = iterations, dropout = dropout, \n",
    "            train_acc_cnn = train_acc_cnn, val_acc_cnn = val_acc_cnn,\n",
    "            test_acc_cnn = test_acc_cnn, test_bin_cnn = test_bin_cnn,\n",
    "            train_acc_ml = train_acc_ml, val_acc_ml = val_acc_ml,\n",
    "            test_acc_ml = test_acc_ml, test_bin_ml = test_bin_ml,\n",
    "            test = test)\n",
    "\n",
    "        import time\n",
    "        time.sleep(10)\n",
    "\n",
    "        from IPython.display import clear_output\n",
    "\n",
    "        clear_output()\n",
    "        \n",
    "    else:\n",
    "        print(\"Skipped: %12s\" % (str(printstate)))\n",
    "\n",
    "# import pandas as pd\n",
    "# df = pd.DataFrame(output)\n",
    "# df.to_csv(\"styloout.csv\", index = False, encoding='utf-8')\n",
    "\n",
    "import time\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
