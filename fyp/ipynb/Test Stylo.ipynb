{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 3)\n",
      "doc_id         int64\n",
      "author_id      int64\n",
      "authorList    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('queryset_CNN.csv')\n",
    "print(df.shape)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current test: doc_id = 85, candidate = 3, dimensions = 200, samples = 300, \n",
      "iterations = 30, dropout = 0.4, test = samplesall\n",
      "Execution completed\n",
      "Running: doc_id = 85, candidate = 3, dimensions = 200, samples = 300, \n",
      "iterations = 30, dropout = 0.4, test = samplesall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 950 (CNMeM is enabled with initial size: 70.0% of memory, cuDNN 5005)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level = Word\n",
      "File used: glove.6B.200d.txt\n",
      "Found 400000 word vectors.\n",
      "Execution completed\n",
      "Read completed\n",
      "Number of rows: 124\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    doc_id = row.doc_id\n",
    "    \n",
    "    author_id = row.author_id\n",
    "    \n",
    "    import ast\n",
    "    authorList = ast.literal_eval(row.authorList)\n",
    "    \n",
    "    val = len(authorList)\n",
    "    \n",
    "    test = \"samplesall\"\n",
    "    \n",
    "    level = \"word\"\n",
    "    \n",
    "    iterations = 30\n",
    "    \n",
    "    dropout = 0.4\n",
    "    \n",
    "    samples = 300\n",
    "    \n",
    "    loc = authorList.index(author_id)\n",
    "    \n",
    "    printstate = ((\"doc_id = %s, candidate = %s, \") % (str(doc_id), str(val)))\n",
    "    printstate += ((\"dimensions = %s, samples = %s, \") % (str(200), str(samples)))\n",
    "    printstate += ((\"\\niterations = %s, dropout = %s, test = %s\") % (str(iterations), str(dropout), str(test)))\n",
    "    \n",
    "    print(\"Current test: %s\" % (str(printstate)))\n",
    "    \n",
    "    import UpdateDB as db\n",
    "    \n",
    "    case = db.checkOldCNN(doc_id = doc_id, candidate = val, dimensions = 200, samples = 300, \n",
    "                          iterations = iterations, dropout = dropout, test = test)\n",
    "    \n",
    "    if case == False:\n",
    "        \n",
    "        print(\"Running: %12s\" % (str(printstate)))\n",
    "        \n",
    "        import StyloNeural as Stylo\n",
    "        (labels_index, predYList, predY, history) = Stylo.getResults(authorList = authorList[:], \n",
    "                                                                     doc_id = doc_id, \n",
    "                                                                     level = level, \n",
    "                                                                     glove = '../../glove/',\n",
    "                                                                     nb_epoch = iterations,\n",
    "                                                                     samples = samples, \n",
    "                                                                     dimensions = 200,\n",
    "                                                                     dropout = dropout\n",
    "                                                                    )\n",
    "        \n",
    "        import UpdateDB as db\n",
    "        db.updateresultOldCNN(doc_id = doc_id, candidate = val, dimensions = 200, samples = samples, \n",
    "                                  iterations = iterations, dropout = dropout, accuracy = predY[loc], test = test)\n",
    "        \n",
    "        from IPython.display import clear_output\n",
    "        clear_output()\n",
    "    \n",
    "    else:\n",
    "        print(\"Skipped: %12s\" % (str(printstate)))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # summarize history for accuracy\n",
    "# plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # summarize history for loss\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
